<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="en">
<head>
<meta charset="utf-8">
<base href="http://dasutt.github.io/stories/interactive-visual-data-analysis/">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Interactive Visual data analysis | Daniel Suttor</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../rss.xml">
<link rel="canonical" href="http://dasutt.github.io/stories/interactive-visual-data-analysis/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Daniel Suttor">
<meta property="og:site_name" content="Daniel Suttor">
<meta property="og:title" content="Interactive Visual data analysis">
<meta property="og:url" content="http://dasutt.github.io/stories/interactive-visual-data-analysis/">
<meta property="og:description" content="Overview
This tool was developed by me and another student during this
practical university course. It was written in C++ and the rendering was implemented
using DirectX 11.
Some of the features we im">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2016-05-27T10:33:00+02:00">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="http://dasutt.github.io/">

                <span id="blog-title">Daniel Suttor</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="../projects/">Projects</a>
                </li>
<li>
<a href="../../archive.html">Archive</a>
                </li>
<li>
<a href="../../categories/">Tags</a>
                </li>
<li>
<a href="../impressum/">About</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<li>
    <a href="index.rst" id="sourcelink">Source</a>
    </li>

                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            
<article class="storypage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Interactive Visual data analysis</a></h1>

        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <div>
<div class="section" id="overview">
<h2>Overview</h2>
<p>This tool was developed by me and another student during <a class="reference external" href="http://wwwcg.in.tum.de/teaching/teaching/winter-term-1516/master-practical-course-interactive-visual-data-analysis.html">this</a>
practical university course. It was written in C++ and the rendering was implemented
using DirectX 11.</p>
<p>Some of the features we implemented were:</p>
<ul class="simple">
<li>mesh rendering</li>
<li>iso surface rendering</li>
<li>direct volume rendering</li>
<li>rendering of metric scalar fields from vector fields</li>
<li>arrow glyph rendering</li>
<li>particle advection and rendering</li>
<li>stream lines, ribbons rendering</li>
<li>Oculus rift support</li>
</ul>
</div>
<div class="section" id="details">
<h2>Details</h2>
<div class="section" id="mesh-rendering">
<h3>Mesh Rendering</h3>
<p>We can load ply 3D mesh files and render them. For this we use simple phong
lighting where the user can specify the objects color.</p>
<img alt="/images/interactive-visual-data-analysis/mesh.png" src="../../images/interactive-visual-data-analysis/mesh.png">
</div>
<div class="section" id="iso-surface-rendering">
<h3>Iso Surface Rendering</h3>
<p>We use Raycasting to render the surface for a user defined iso value. The ray marching
is implemented by drawing a simple cube and computing the entry and exit points of the rays.
The 3D Texture containing the data is sampled with a fixed step size to find the intersection
point of the ray with the iso value.</p>
<p>To improve the precision of the ray marching we perform a binary search after we
found the iso value. Using central differences we calculate the surface normals
for each point our rays hit. With this we can use phong lighting on the iso surface.
The results of the rendering can be seen below. In this case a human head with different
iso values is rendered. With this it is possible to show the skull or the whole head.</p>
<img alt="/images/interactive-visual-data-analysis/iso.png" src="../../images/interactive-visual-data-analysis/iso.png">
</div>
<div class="section" id="direct-volume-rendering">
<h3>Direct Volume Rendering</h3>
<p>Similiar to iso surface rendering we use the same ray marching approach for direct
volume rendering. However instead of defining a single iso value and stopping the ray
at this intersection we use a transfer function to determine which values add to the overall color
At each grid point along the ray we sample this transfer functions to get a value at this point.
These values are accumulated until the alpha value is close to one or if we reached the end of
the volume.</p>
<p>The major advantage in comparison to the iso surface rendering is the control the user
has over the rendering. In comparison to the iso surface images it is possible to display
the skull and the head at the same time.</p>
<img alt="/images/interactive-visual-data-analysis/dvr.png" src="../../images/interactive-visual-data-analysis/dvr.png">
</div>
<div class="section" id="rendering-of-metric-scalar-fields-from-vector-fields">
<h3>rendering of metric scalar fields from vector fields</h3>
<p>For the iso surface rendering and direct volume rendering the surfaces are determined
by a single value like the density. When using vector fields as an input for our renderer
we have to determine which how to interpret the data provided.</p>
<p>We perform different calculations on the vector data like velocity and vorticity
magnitudes or the divergence.</p>
<p>We also implemented support for time dependent data by interpolating the values at
the current time step between time slices of the scalar and vector texture data.</p>
</div>
<div class="section" id="arrow-glyph-rendering">
<h3>arrow glyph rendering</h3>
<p>Another way to display the computed metric values is through arrow glyphs. We use the
geometry shader to create the arrow glyphs based on the magnitude and direction of the
data.</p>
<p>The axis and position of the arrow glyph slice can be changed by the user.</p>
</div>
<div class="section" id="particle-advection-and-rendering">
<h3>particle advection and rendering</h3>
<p>To improve the display of the overall movement in the time dependent data we use particles
computed on the GPU. The user can place probe volumes in the data sets that will emit particles
into the scene. Parameters like particle size, color, lifetime and the amount can be controlled
by the user</p>
<p>The particles are advected during their lifetime based on the values of the vector field.
For the rendering we implemented two different ways: The simplest one is just rendering
the particles as point primitives at their calculated positions. The visually more appealing
version is using billboards. We use the geometry shader to create quads around the particle
positions and calculate a sphere based on camera distance and position which is then used
to perform lighting calculations</p>
<img alt="/images/interactive-visual-data-analysis/Ellipsoid_probes.png" src="../../images/interactive-visual-data-analysis/Ellipsoid_probes.png">
</div>
<div class="section" id="stream-lines-ribbons-rendering">
<h3>stream lines, ribbons rendering</h3>
<p>Besides the advection of particles we also allow for the calculation of stream lines and
ribbons. Both of them can be rendered as simple line lists with varying colors based on
the magnitude of the velocity</p>
<p>The stream lines can also be rendered as tubes. Similar to the rendering of the particles
we use the geometry shader to create billboards and compute the position of the resulting
geometry for the lighting analytically.</p>
<p>The ribbons can be rendered out of multiple lines and then connected to better visualize
the movement of the field.</p>
<img alt="/images/interactive-visual-data-analysis/Ellipsoid_StreamLines_Ribbons.png" src="../../images/interactive-visual-data-analysis/Ellipsoid_StreamLines_Ribbons.png">
</div>
<div class="section" id="oculus-rift-support">
<h3>Oculus rift support</h3>
<p>For the final presentation we decided to add Oculus Rift support to our application.
In comparison to my bachelor thesis this proved to be quite easy because the SDK
for Oculus is taking care of almost everything now. However we had to be careful to always
use the correct values for our projections because a lot of our rendering is based on this.</p>
</div>
</div>
</div>
    </div>
    

</article>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents Â© 2016         <a href="mailto:mail@danielsuttor.de">Daniel Suttor</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
        </footer>
</div>
</div>


            <script src="../../assets/js/all-nocdn.js"></script><script>$('a.image-reference:not(.islink) img:not(.islink)').parent().colorbox({rel:"gal",maxWidth:"100%",maxHeight:"100%",scalePhotos:true});</script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates -->
</body>
</html>
